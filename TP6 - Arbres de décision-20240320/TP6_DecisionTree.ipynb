{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53de3c09",
   "metadata": {},
   "source": [
    "# Introduction aux arbres de décision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4db635e1",
   "metadata": {},
   "source": [
    "Comme étudié dans la feuille de TD2, les arbres de décisions structurent un ensemble de règles de décisions sous la forme d'un arbre. Dans ce TP, nous allons utiliser des algorithmes d'apprentissage d'arbres de décision sur des données réelles et étudier leur capacité à prédire la classe de nouvelles données. Cette étude nous permettra d'appréhender le concept d'**over-fitting**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0de292fb",
   "metadata": {},
   "source": [
    "## A. Préparation du dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ded0e13",
   "metadata": {},
   "source": [
    "Le dataset `breast-cancer.data` comporte la description de près de 300 patientes atteintes d'un cancer du sein et examinées dans un institut d'oncologie en Slovénie. La tâche consiste à prédire le risque de récidive pour la patiente à partir des 9 descripteurs catégoriels suivants :\n",
    "\n",
    "|  Type  |    Catégorie    |\n",
    "| :---------:|---------|\n",
    "| age | âge de la patiente|\n",
    "| menopause | statut ménopausal |\n",
    "| tumor-size | taille de la tumeur|\n",
    "| inv-nodes | nombre de ganglions invasifs |\n",
    "| node-caps | capsule ganglionnaire |\n",
    "| deg-malig | Degré de malignité |\n",
    "| breast | sein (gauche ou droit) |\n",
    "| breast-quad | quadrant mammaire |\n",
    "| irradiat | radiothérapie |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a82feb",
   "metadata": {},
   "source": [
    "Chargez le dataset dans un dataframe `patient` et vérifiez les données récupérées (taille, valeurs manquantes, nature des descripteurs, déséquilibre des classes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aaece2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eee0414",
   "metadata": {},
   "source": [
    "Procédez à l'extraction des descriptions et des labels de classes dans deux tableaux Numpy :\n",
    "- `X` pour la matrice des descriptions (286 x 9)\n",
    "- `y` pour le vecteur des labels de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192a840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab0411a0",
   "metadata": {},
   "source": [
    "## B. One-hot encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a82cadce",
   "metadata": {},
   "source": [
    "Utilisez le [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) de Scikit-learn pour transformer votre matrice `X` en une matrice binaire `Xbin` où une variable catégorielle initiale avec $k$ modalités sera décomposée en $k$ variables binaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5554d8d4",
   "metadata": {},
   "source": [
    "Observez la forme de la matrice récupérée (nombre de variables) et le type particulier de cette matrice. Documentez-vous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033ac81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a1f64dc",
   "metadata": {},
   "source": [
    "Vérfiez la transformation opérée sur la première variable catégorielle `age` :\n",
    "- observez le nombre $k$ de modalités (valeurs) pour cette variable\n",
    "- vérifiez que chaque ligne de `Xbin` contient exactement une composante à 1 (et toutes les autres à 0) sur les $k$ premières composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1d3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c729cb83",
   "metadata": {},
   "source": [
    "## C. Apprentissage d'un arbre de décision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be6c6962",
   "metadata": {},
   "source": [
    "Utilisez la librairie Scikit-learn pour découper `Xbin` (et `y`) en deux sous-ensembles (`X_train`, `y_train`) et (`X_test`, `y_test`). On procèdera pour ce TP à un découpage en sous-ensembles de mêmes tailles (50/50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583fd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9689008",
   "metadata": {},
   "source": [
    "> <br/>Scikit-learn propose une implémentation assez générique des arbres de décision. Le constructeur d'un [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) permet de paramétrer la méthode d'apprentissage ainsi que certaines propriétés attendues sur la structure de l'arbre. Notamment :\n",
    "> - le paramètre `criterion` definit la mesure de qualité utilisée pour le découpage : `'gini'` (par défaut), `'entropy'` (vu en TD) ou `'log_loss'`\n",
    "> - le paramètre `min_sample_leaf` definit le nombre minimum d'individus autorisés dans les feuilles de l'arbre (1 par défaut) <br/><br/>\n",
    ">\n",
    "> Un arbre de décision (`DecisionTreeClassifier`) peut ensuite être manipulé à partir de deux méthodes :\n",
    "> - `.fit(X, y)` qui permet d'apprendre un arbre de décision à partir d'un dataset d'entraînement `(X, y)` où <br/> <br/>\n",
    ">   - `X` contient des descriptions (numériques ou binaires)\n",
    ">   - `y` contient les labels de classes associés.<br/> <br/>\n",
    "> - `.predict(X)` qui permet de prédire la classe de chaque individu du dataset `X` <br/>  <br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d56cb511",
   "metadata": {},
   "source": [
    "Apprendre un arbre de décision sur les données d'entraînement en utilisant l'entropie comme critère de découpage et en conservant les propriétés structurelles par défaut. Stockez votre modèle de prédiction (arbre de décision) dans une variable `dtree`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d81095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d64e9c1",
   "metadata": {},
   "source": [
    "La commande suivante vous offre une visualisation du modèle appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "tree.plot_tree(dtree, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a0fb1d8",
   "metadata": {},
   "source": [
    "Utilisez les paramètres de votre `OneHotEncoder` pour donner du sens aux descripteurs utilisés dans les noeuds de l'arbre de décision :\n",
    "- l'attribut `categories_` décrit les nouvelles variables binaires construites à partir de chaque variables catégorielle initiale\n",
    "- la méthode `.get_feature_names_out()` retourne la liste de toutes les variables binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923fede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14afd0af",
   "metadata": {},
   "source": [
    "Observez quelques propriétés structurelles de l'arbre de décision :\n",
    "- nombre de feuilles (sont-elles toutes pures?)\n",
    "- profondeur de l'arbre "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dcff5a1",
   "metadata": {},
   "source": [
    "Vérifiez ces propriétés en utilisant les attributs de votre objet `dtree` (`.get_n_leaves()`, `.get_depth()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b38d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63616505",
   "metadata": {},
   "source": [
    "## D. Over-fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5dcfa21",
   "metadata": {},
   "source": [
    "Calculez et comparer les taux d'erreurs de prédiction sur :\n",
    "- les données d'entraînement `X_train` qui ont servi à construire l'arbre de décision\n",
    "- les données de test `X_test` qui n'ont jamais été utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af532d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b7586a2",
   "metadata": {},
   "source": [
    "Comment expliquez-vous cette différence?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3808aabf",
   "metadata": {},
   "source": [
    "Apprenez un nouvel arbre de décision moins profond à partir de `X_train` toujours (par exemple avec `min_sample_leaf=5`). Observez ses propriétés structurelles puis ses performances (taux d'erreur sur `X_train` puis sur `X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0c593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3704a0fd",
   "metadata": {},
   "source": [
    "> On parle d'<font color='red'>over-fitting</font> (sur-adéquation aux données) lorsqu'un modèle $f$ appris est très performant sur les données utilisées pour l'apprentissage mais n'ai pas suffisamment générique pour prédire sur de nouvelles données (données de test).\n",
    "> Pour détecter l'over-fitting on compare :\n",
    "> - l'<font color='red'>erreur d'apprentissage</font> $e_{train}(f)$: taux d'erreur sur les données d'entraînement (`X_train`)\n",
    "> - l'<font color='red'>erreur de généralisation</font> $e_{test}(f)$: taux d'erreur sur les données de test (`X_test`)\n",
    ">\n",
    "> Le modèle $f$ est sujet à over-fitting si $e_{test}(f) \\gg e_{train}(f)$\n",
    "> <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "921c492c",
   "metadata": {},
   "source": [
    "> Une manière de réduire l'over-fitting des arbres de décision consiste à limiter la taille des règles de décision (et donc la profondeur de l'arbre) :\n",
    "> - des règles de décision trop longues ont peu de chance d'être satisfaites par de nouveaux exemples (règles trop spécifiques)\n",
    "> - des règles de décision courtes ont plus de chance d'être satisfaite par de nouveaux exemples (règles plus générales) <br/><br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5ce0ef4",
   "metadata": {},
   "source": [
    "Ecrire un fonction `eval_DT(X_train, y_train, X_test, y_test, min_samples_leaf)` qui retourne l'erreur d'apprentissage et l'erreur de généralisation d'un arbre de décision de profonduer contrôlée par `min_samples_leaf`, appris sur `X_train` et testé sur `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb11a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_DT(X_train, y_train, X_test, y_test, min_samples_leaf):\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a449d1e7",
   "metadata": {},
   "source": [
    "Etudiez le phénomène d'over-fitting sur les données `breast-cancer`. Pour cela :\n",
    "- calculez les erreurs d'apprentissage et de généralisation en faisant évoluer la profondeur de l'arbre (ex. `min_samples_leaf` variant de 1 à 50)\n",
    "- tracez les courbes associées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddab8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4bbb64",
   "metadata": {},
   "source": [
    "Ré-executez votre notebook pour voir dans quelle mesure le phénomène d'over-fitting est sensible au (découpage du) dataset. Faites également évoluer la proportion d'exemples utilisés pour apprendre l'arbre de décision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
